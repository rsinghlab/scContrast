{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7908b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "script_dir = Path().resolve()\n",
    "repo_dir = script_dir\n",
    "src_dir = repo_dir / 'src'\n",
    "data_dir = repo_dir / 'data'\n",
    "sys.path.append(str(src_dir))\n",
    "sys.path.append(str(data_dir))\n",
    "\n",
    "from dataset.dataloader import AnnDataDataset\n",
    "\n",
    "PARAMETERS = {\n",
    "    'hvgs': 20116,\n",
    "    'num_genes': 20116,\n",
    "    # 'hvgs': 5000,\n",
    "    # 'num_genes': 5000,\n",
    "    'latent_dimension': 50,\n",
    "    'target_sum': 10000,\n",
    "    'batch_size': 128,\n",
    "    'num_epochs': 1,\n",
    "}\n",
    "\n",
    "tm_droplet_data = sc.read(\n",
    "    r'./data/raw/tabula_muris/TM_droplet.h5ad',\n",
    "    # backup_url=\"https://figshare.com/ndownloader/files/23938934\",\n",
    ")\n",
    "tm_facs_data = sc.read(\n",
    "    r'./data/raw/tabula_muris/TM_facs.h5ad',\n",
    "    # backup_url=\"https://figshare.com/ndownloader/files/23939711\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ede9b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm_droplet_data_tissues={'Limb_Muscle', 'Heart_and_Aorta', 'Fat', 'Kidney', 'Bladder', 'Tongue', 'Liver', 'Mammary_Gland', 'Skin', 'Pancreas', 'Thymus', 'Trachea', 'Marrow', 'Large_Intestine', 'Spleen', 'Lung'}\n",
      "len(tm_droplet_data_tissues)=16\n",
      "tm_facs_data_tissues={'Limb_Muscle', 'Kidney', 'SCAT', 'Skin', 'Large_Intestine', 'Diaphragm', 'Brain_Non-Myeloid', 'Brain_Myeloid', 'Marrow', 'Lung', 'Liver', 'Pancreas', 'Thymus', 'Heart', 'Trachea', 'Spleen', 'Aorta', 'BAT', 'Bladder', 'Tongue', 'Mammary_Gland', 'GAT', 'MAT'}\n",
      "len(tm_facs_data_tissues)=23\n",
      "len(tm_all_tissues)=25\n",
      "{'Kidney', 'SCAT', 'Thymus', 'Heart', 'Trachea', 'Large_Intestine', 'Spleen', 'Aorta', 'Heart_and_Aorta', 'BAT', 'Fat', 'Bladder', 'Diaphragm', 'Tongue', 'Brain_Non-Myeloid', 'Mammary_Gland', 'Brain_Myeloid', 'Marrow', 'MAT', 'GAT', 'Lung'}\n",
      "{'Limb_Muscle', 'Pancreas', 'Liver', 'Skin'}\n"
     ]
    }
   ],
   "source": [
    "tm_droplet_data_tissues = tm_droplet_data.obs.tissue.tolist()\n",
    "tm_droplet_data_tissues = {t for t in tm_droplet_data_tissues}\n",
    "tm_droplet_data_tissues\n",
    "print(f'{tm_droplet_data_tissues=}')\n",
    "print(f'{len(tm_droplet_data_tissues)=}')\n",
    "\n",
    "tm_facs_data_tissues = tm_facs_data.obs.tissue.tolist()\n",
    "tm_facs_data_tissues = {t for t in tm_facs_data_tissues}\n",
    "tm_facs_data_tissues\n",
    "print(f'{tm_facs_data_tissues=}')\n",
    "print(f'{len(tm_facs_data_tissues)=}')\n",
    "\n",
    "tm_all_tissues = tm_droplet_data_tissues.union(tm_facs_data_tissues)\n",
    "# tm_all_tissues\n",
    "print(f'{len(tm_all_tissues)=}')\n",
    "\n",
    "# train_tissues = tm_shared_tissues[:-4]\n",
    "# test_tissues = tm_shared_tissues[-4:]\n",
    "\n",
    "# print(f'{train_tissues=}')\n",
    "# print(f'{test_tissues=}')\n",
    "\n",
    "# train_tissues=['Large_Intestine', 'Spleen', 'Mammary_Gland', 'Lung', 'Kidney', 'Thymus', 'Bladder', 'Tongue', 'Marrow', 'Trachea']\n",
    "test_tissues={'Skin', 'Liver', 'Limb_Muscle', 'Pancreas'}\n",
    "train_tissues = tm_all_tissues.difference(test_tissues) # v3,5\n",
    "print(train_tissues)\n",
    "print(test_tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07813015",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_droplet_data = tm_droplet_data[\n",
    "    (~tm_droplet_data.obs.cell_ontology_class.isna())\n",
    "].copy()\n",
    "tm_facs_data = tm_facs_data[\n",
    "    (~tm_facs_data.obs.cell_ontology_class.isna())\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d918101b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e59bb4ed-34ac-4d03-85b9-27e06fa7d292",
       "rows": [
        [
         "0610007C21Rik",
         "94.5714285714286"
        ],
        [
         "0610007L01Rik",
         "156.0"
        ],
        [
         "0610007P08Rik",
         "202.272727272727"
        ],
        [
         "0610007P14Rik",
         "104.0"
        ],
        [
         "0610007P22Rik",
         "158.75"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0610007C21Rik</th>\n",
       "      <td>94.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610007L01Rik</th>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610007P08Rik</th>\n",
       "      <td>202.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610007P14Rik</th>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610007P22Rik</th>\n",
       "      <td>158.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        1\n",
       "0                        \n",
       "0610007C21Rik   94.571429\n",
       "0610007L01Rik  156.000000\n",
       "0610007P08Rik  202.272727\n",
       "0610007P14Rik  104.000000\n",
       "0610007P22Rik  158.750000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_len = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/chenlingantelope/HarmonizationSCANVI/master/data/gene_len.txt\",\n",
    "    delimiter=\" \",\n",
    "    header=None,\n",
    "    index_col=0,\n",
    ")\n",
    "gene_len.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecbf3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "gene_len = gene_len.reindex(tm_facs_data.var.index).dropna()\n",
    "\n",
    "tm_facs_data = tm_facs_data[:, gene_len.index].copy()   # break the view\n",
    "\n",
    "gene_len_vec = gene_len[1].values.astype(np.float32)\n",
    "median_len  = np.median(gene_len_vec)\n",
    "\n",
    "# column‑wise scaling in CSC format\n",
    "X = tm_facs_data.X.tocsc(copy=True)        # -> (n_cells × n_genes)\n",
    "X = X.multiply(1.0 / gene_len_vec)         # divide each column by its length\n",
    "X = X.multiply(median_len)                 # multiply by the median length\n",
    "X.data = np.rint(X.data)                   # round only the non‑zero entries\n",
    "\n",
    "tm_facs_data.X = X.tocsr()                 # store back as CSR (Scanpy’s default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab32c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336005/826039316.py:13: FutureWarning: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  tm_adata_train = tm_droplet_train.concatenate(tm_facs_train)\n"
     ]
    }
   ],
   "source": [
    "tm_droplet_train = tm_droplet_data[\n",
    "    (tm_droplet_data.obs['tissue'].isin(train_tissues))  \n",
    "    & (~tm_droplet_data.obs.cell_ontology_class.isna())\n",
    "].copy()\n",
    "\n",
    "tm_facs_train = tm_facs_data[\n",
    "    (tm_facs_data.obs['tissue'].isin(train_tissues))  \n",
    "    & (~tm_facs_data.obs.cell_ontology_class.isna())\n",
    "].copy()\n",
    "\n",
    "tm_droplet_train.obs[\"tech\"] = \"10x\"\n",
    "tm_facs_train.obs[\"tech\"] = \"SS2\"\n",
    "tm_adata_train = tm_droplet_train.concatenate(tm_facs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34bbebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336005/948500612.py:13: FutureWarning: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  tm_adata_test = tm_droplet_test.concatenate(tm_facs_test)\n"
     ]
    }
   ],
   "source": [
    "tm_droplet_test = tm_droplet_data[\n",
    "    (tm_droplet_data.obs['tissue'].isin(test_tissues))  \n",
    "    & (~tm_droplet_data.obs.cell_ontology_class.isna())\n",
    "].copy()\n",
    "\n",
    "tm_facs_test = tm_facs_data[\n",
    "    (tm_facs_data.obs['tissue'].isin(test_tissues))  \n",
    "    & (~tm_facs_data.obs.cell_ontology_class.isna())\n",
    "].copy()\n",
    "\n",
    "tm_droplet_test.obs[\"tech\"] = \"10x\"\n",
    "tm_facs_test.obs[\"tech\"] = \"SS2\"\n",
    "tm_adata_test = tm_droplet_test.concatenate(tm_facs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1415ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tm_adata_train)=294439\n",
      "len(tm_adata_test)=61774\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(tm_adata_train)=}')\n",
    "print(f'{len(tm_adata_test)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cea683b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(tm_adata_train, target_sum=1e4)\n",
    "sc.pp.log1p(tm_adata_train)\n",
    "sc.pp.highly_variable_genes(\n",
    "    tm_adata_train,\n",
    "    batch_key=\"tech\",\n",
    ")\n",
    "\n",
    "tm_adata_train.X = np.nan_to_num(tm_adata_train.X, nan=0)\n",
    "\n",
    "num_genes = len(tm_adata_train.var.index)\n",
    "PARAMETERS['hvgs'] = num_genes\n",
    "\n",
    "hvg_genes = tm_adata_train.var.index[tm_adata_train.var['highly_variable']].tolist()\n",
    "\n",
    "# tm_adata_train = tm_adata_train[:, tm_adata_train.var.index.isin(hvg_genes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c171782",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(tm_adata_test, target_sum=1e4)\n",
    "sc.pp.log1p(tm_adata_test)\n",
    "\n",
    "tm_adata_test.X = np.nan_to_num(tm_adata_test.X, nan=0)\n",
    "\n",
    "# tm_adata_test = tm_adata_test[:, tm_adata_test.var.index.isin(hvg_genes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0c73a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 61774 × 18244\n",
       "    obs: 'age', 'cell', 'Celltype', 'cell_ontology_id', 'free_annotation', 'method', 'mouse.id', 'n_genes', 'sex', 'subtissue', 'tissue', 'tissue_free_annotation', 'tech', 'FACS.selection', 'n_counts', 'batch'\n",
       "    var: 'n_cells-0', 'n_cells-1'\n",
       "    uns: 'log1p'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_adata_train.obs.rename(columns={'cell_ontology_class': 'Celltype'}, inplace=True)\n",
    "tm_adata_test.obs.rename(columns={'cell_ontology_class': 'Celltype'}, inplace=True)\n",
    "tm_adata_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42219cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336005/696334384.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  celltype_techs = tm_adata_train.obs.groupby(\"Celltype\")[\"tech\"].unique()\n"
     ]
    }
   ],
   "source": [
    "celltype_techs = tm_adata_train.obs.groupby(\"Celltype\")[\"tech\"].unique()\n",
    "\n",
    "# 2) Build a dictionary mapping each cell type to \"only_10x\", \"only_SS2\", or \"both\"\n",
    "celltype_status = {}\n",
    "for celltype, tech_list in celltype_techs.items():\n",
    "    tech_set = set(tech_list)\n",
    "    if len(tech_set) == 1:\n",
    "        if \"10x\" in tech_set:\n",
    "            celltype_status[celltype] = \"only_10x\"\n",
    "        else:\n",
    "            celltype_status[celltype] = \"only_SS2\"\n",
    "    else:\n",
    "        celltype_status[celltype] = \"both\"\n",
    "\n",
    "# 3) Create a new column in .obs indicating whether a cell's type is only_10x, only_SS2, or both\n",
    "tm_adata_train.obs[\"celltype_tech_availability\"] = (\n",
    "    tm_adata_train.obs[\"Celltype\"].map(celltype_status)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eebe2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336005/182291955.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  celltype_techs = tm_adata_test.obs.groupby(\"Celltype\")[\"tech\"].unique()\n"
     ]
    }
   ],
   "source": [
    "celltype_techs = tm_adata_test.obs.groupby(\"Celltype\")[\"tech\"].unique()\n",
    "\n",
    "# 2) Build a dictionary mapping each cell type to \"only_10x\", \"only_SS2\", or \"both\"\n",
    "celltype_status = {}\n",
    "for celltype, tech_list in celltype_techs.items():\n",
    "    tech_set = set(tech_list)\n",
    "    if len(tech_set) == 1:\n",
    "        if \"10x\" in tech_set:\n",
    "            celltype_status[celltype] = \"only_10x\"\n",
    "        else:\n",
    "            celltype_status[celltype] = \"only_SS2\"\n",
    "    else:\n",
    "        celltype_status[celltype] = \"both\"\n",
    "\n",
    "# 3) Create a new column in .obs indicating whether a cell's type is only_10x, only_SS2, or both\n",
    "tm_adata_test.obs[\"celltype_tech_availability\"] = (\n",
    "    tm_adata_test.obs[\"Celltype\"].map(celltype_status)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf788499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336005/830236323.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  tm_adata_test.obs['Celltype'].replace(\n",
      "/tmp/ipykernel_336005/830236323.py:1: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  tm_adata_test.obs['Celltype'].replace(\n"
     ]
    }
   ],
   "source": [
    "tm_adata_test.obs['Celltype'].replace(\n",
    "    to_replace='pancreatic ductal cel',\n",
    "    value='pancreatic ductal cell',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d48c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "AAACCTGAGATGTCGG-1-9-0-0-0           both\n",
       "AAAGCAATCGGAAATA-1-9-0-0-0           both\n",
       "AAAGTAGAGGCCCTTG-1-9-0-0-0           both\n",
       "AACCGCGAGAAACCGC-1-9-0-0-0           both\n",
       "AACTCCCAGTTGTCGT-1-9-0-0-0           both\n",
       "                                   ...   \n",
       "P9.MAA000907.3_11_M.1.1-1-1-1        both\n",
       "P9.MAA000927.3_9_M.1.1-1-1-1     only_SS2\n",
       "P9.MAA000938.3_8_M.1.1-1-1-1     only_SS2\n",
       "P9.MAA001857.3_38_F.1.1-1-1-1        both\n",
       "P9.MAA001861.3_39_F.1.1-1-1-1        both\n",
       "Name: celltype_tech_availability, Length: 61774, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_adata_test.obs['celltype_tech_availability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "script_dir = Path().resolve()\n",
    "repo_dir = script_dir\n",
    "src_dir = repo_dir / 'src'\n",
    "data_dir = repo_dir / 'data'\n",
    "sys.path.append(str(src_dir))\n",
    "sys.path.append(str(data_dir))\n",
    "\n",
    "from dataset.dataloader import AnnDataDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d62d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_dataset = AnnDataDataset(tm_adata_train)\n",
    "tm_dataloader = DataLoader(tm_dataset, batch_size=PARAMETERS['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./data/pickled/tabula_muris/tm_dataset_train_tissues_length_normalized_v3,5.pkl', 'wb') as f: # NOTE: 3,5 because apparently v3 already has both sexes\n",
    "    pickle.dump(tm_dataset, f)\n",
    "\n",
    "with open(r'./data/pickled/tabula_muris/tm_dataloader_train_tissues_length_normalized_v3,5.pkl', 'wb') as f:\n",
    "    pickle.dump(tm_dataloader, f)\n",
    "\n",
    "with open(r'./data/pickled/tabula_muris/tm_adata_train_length_normalized_v3,5.pkl', 'wb') as f:\n",
    "    pickle.dump(tm_adata_train, f)\n",
    "\n",
    "# with open(r'./data/pickled/tabula_muris/tm_adata_test_v3,5.pkl', 'wb') as f: # NOTE: v3 test already has both sex test tissues\n",
    "#     pickle.dump(tm_adata_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to precompute data-dependent variables\n",
    "def precompute_gene_clusters(dataset):\n",
    "    most_significant_genes_dict = dataset.most_significant_genes_dict\n",
    "    least_significant_genes_dict = dataset.least_significant_genes_dict\n",
    "    gene_networks = dataset.gene_networks\n",
    "    cell_type_categories = dataset.cell_type_categories\n",
    "    code_to_celltype = dataset.code_to_celltype\n",
    "    celltype_to_code = dataset.celltype_to_code\n",
    "    gene_names = dataset.gene_names\n",
    "    gene_name_to_index = dataset.gene_name_to_index\n",
    "    index_to_gene_name = dataset.index_to_gene_name\n",
    "    gene_dispersions = dataset.gene_dispersions\n",
    "    print('Precomputed gene clusters!')\n",
    "    return (most_significant_genes_dict, least_significant_genes_dict,\n",
    "            gene_networks, gene_names, code_to_celltype, celltype_to_code,\n",
    "            gene_name_to_index, index_to_gene_name, gene_dispersions)\n",
    "\n",
    "def precompute_mu_sigma(dataloader, most_significant_genes_dict, least_significant_genes_dict, gene_name_to_index):\n",
    "    all_expression_matrix = []\n",
    "    cell_types_data = {}\n",
    "    cell_types_msg_data = {}\n",
    "    cell_types_lsg_data = {}\n",
    "    for batch in dataloader:\n",
    "        expression_matrix, cell_types = batch\n",
    "        all_expression_matrix.append(expression_matrix)\n",
    "        \n",
    "        for cell_type in torch.unique(cell_types):\n",
    "            cell_type = int(cell_type)\n",
    "            cell_type_mask = cell_types == cell_type\n",
    "            cell_type_expression_matrix = expression_matrix[cell_type_mask]\n",
    "            # All genes\n",
    "            if cell_type not in cell_types_data:\n",
    "                cell_types_data[cell_type] = []\n",
    "            cell_types_data[cell_type].append(cell_type_expression_matrix)\n",
    "\n",
    "            # Most significant genes\n",
    "            msg_genes = most_significant_genes_dict[cell_type]\n",
    "            msg_gene_indices = [gene_name_to_index[g] for g in msg_genes]\n",
    "            msg_significant_gene_matrix = cell_type_expression_matrix[:, msg_gene_indices]\n",
    "            if cell_type not in cell_types_msg_data:\n",
    "                cell_types_msg_data[cell_type] = []\n",
    "            cell_types_msg_data[cell_type].append(msg_significant_gene_matrix)\n",
    "            \n",
    "            # Least significant genes\n",
    "            lsg_genes = least_significant_genes_dict[cell_type]\n",
    "            lsg_gene_indices = [gene_name_to_index[g] for g in lsg_genes]\n",
    "            lsg_significant_gene_matrix = cell_type_expression_matrix[:, lsg_gene_indices]\n",
    "            if cell_type not in cell_types_lsg_data:\n",
    "                cell_types_lsg_data[cell_type] = []\n",
    "            cell_types_lsg_data[cell_type].append(lsg_significant_gene_matrix)\n",
    "\n",
    "    cell_type_mu_sigma = {}\n",
    "    cell_type_msg_mu_sigma = {}\n",
    "    cell_type_lsg_mu_sigma = {}\n",
    "    # All genes\n",
    "    for cell_type, cell_type_expression_matrix in cell_types_data.items():\n",
    "        data_tensor = torch.cat(cell_type_expression_matrix, dim=0)\n",
    "        mu = torch.mean(data_tensor, dim=0)\n",
    "        sigma = torch.std(data_tensor, dim=0, unbiased=False)\n",
    "        sigma = torch.clamp(sigma, min=1e-8)\n",
    "        cell_type_mu_sigma[int(cell_type)] = (mu, sigma)\n",
    "    \n",
    "    # Most significant genes\n",
    "    for cell_type, matrices in cell_types_msg_data.items():\n",
    "        data_tensor = torch.cat(matrices, dim=0)\n",
    "        mu = torch.mean(data_tensor, dim=0)\n",
    "        sigma = torch.std(data_tensor, dim=0, unbiased=False)\n",
    "        sigma = torch.clamp(sigma, min=1e-8)\n",
    "        dispersion = sigma**2 / mu\n",
    "        cell_type_msg_mu_sigma[int(cell_type)] = (mu, sigma, dispersion)\n",
    "    \n",
    "    # Least significant genes\n",
    "    for cell_type, matrices in cell_types_lsg_data.items():\n",
    "        data_tensor = torch.cat(matrices, dim=0)\n",
    "        mu = torch.mean(data_tensor, dim=0)\n",
    "        sigma = torch.std(data_tensor, dim=0, unbiased=False)\n",
    "        sigma = torch.clamp(sigma, min=1e-8)\n",
    "        dispersion = sigma**2 / mu\n",
    "        cell_type_lsg_mu_sigma[int(cell_type)] = (mu, sigma, dispersion)\n",
    "\n",
    "    data_tensor = torch.cat(all_expression_matrix, dim=0)\n",
    "    global_mu_sigma = (torch.mean(data_tensor, dim=0),\n",
    "                       torch.std(data_tensor, dim=0, unbiased=False))\n",
    "\n",
    "    return cell_type_mu_sigma, global_mu_sigma, cell_type_msg_mu_sigma, cell_type_lsg_mu_sigma\n",
    "\n",
    "# Precompute data-dependent variables before model initialization\n",
    "(most_significant_genes_dict, least_significant_genes_dict,\n",
    " gene_networks, gene_names, code_to_celltype, celltype_to_code,\n",
    " gene_name_to_index, index_to_gene_name, gene_dispersions) = precompute_gene_clusters(tm_dataset)\n",
    "\n",
    "cell_type_mu_sigma, global_mu_sigma, cell_type_msg_mu_sigma, cell_type_lsg_mu_sigma = precompute_mu_sigma(\n",
    "    tm_dataloader, most_significant_genes_dict, least_significant_genes_dict, gene_name_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90301f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_dir = data_dir / 'pickled' / 'tabula_muris' / 'precomputed'\n",
    "precomputed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "precomputed_gene_clusters_path =  precomputed_dir / 'tm_dataset_train_tissues_length_normalized_v3,5_precomputed_gene_clusters.pkl'\n",
    "with open(precomputed_gene_clusters_path, 'wb') as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"most_significant_genes_dict\": most_significant_genes_dict,\n",
    "            \"least_significant_genes_dict\": least_significant_genes_dict,\n",
    "            \"gene_networks\": gene_networks,\n",
    "            \"gene_names\": gene_names,\n",
    "            \"code_to_celltype\": code_to_celltype,\n",
    "            \"celltype_to_code\": celltype_to_code,\n",
    "            \"gene_name_to_index\": gene_name_to_index,\n",
    "            \"index_to_gene_name\": index_to_gene_name,\n",
    "            \"gene_dispersions\": gene_dispersions,\n",
    "        },\n",
    "        f,\n",
    "    )\n",
    "\n",
    "precomputed_mu_sigma_path = precomputed_dir / 'tm_dataset_train_tissues_length_normalized_v3,5_precomputed_mu_sigma.pkl'\n",
    "with open(precomputed_mu_sigma_path, \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"cell_type_mu_sigma\": cell_type_mu_sigma,\n",
    "            \"global_mu_sigma\": global_mu_sigma,\n",
    "            \"cell_type_msg_mu_sigma\": cell_type_msg_mu_sigma,\n",
    "            \"cell_type_lsg_mu_sigma\": cell_type_lsg_mu_sigma,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6be8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch.venv",
   "language": "python",
   "name": "pytorch.venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
